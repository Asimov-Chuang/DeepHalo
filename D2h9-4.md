We thank Reviewer D2h9 for their positive recognition of our work. In the revision, we will include a model architecture diagram and correct the noted typos. Below, we provide point-by-point responses to the reviewer’s comments.


### Responses to Weakness

1. xxxxxx Refer to xxxx.

2. 

#### 1. Clarifying the relationship between DeepHalo and Transformer architectures

This is a highly insightful observation. Indeed, the connection to Transformer-style architectures is deeply embedded in the design of our approach, and we appreciate the opportunity to elaborate on this relationship.

We begin with the featureless setting, where modeling higher-order context effects reduces to polynomial regression over indicator functions that encode item presence. DeepHalo introduces a structured and recursive mechanism to capture subset-level interactions in this setting, conceptually analogous to the accumulation of interactions based on binary inclusion indicators.

In the feature-rich setting, the core challenge is to encode interactions among a subset of items using their feature representations, while strictly excluding information from outside the subset. This naturally recalls the concept of attention scores, typically computed from item feature pairs. However, when these scores are normalized via a softmax function, the resulting attention weights entangle all item features—thus violating the independence required for controlled halo modeling. To address this, we omit softmax normalization, and further observe that the dot-product attention mechanism is not essential for modeling decomposable utility functions. This insight motivates a simplification of the architecture, leading to the formulations presented in Equations (4) and (5).

In summary, there are several critical differences between DeepHalo and Transformers, both structurally and in modeling implications:

- **Effect order control**:  
  Transformers (e.g., in TCNet) implicitly allow interactions across all items, resulting in **full-order interactions** (order $|S| - 1$).  
  In contrast, DeepHalo provides explicit layer-wise control, where each layer adds exactly one level of interaction (or $\times 2$ with quadratic activation). This control is essential for interpretability, regularization, and tractability.

- **Structural simplification**:  
  DeepHalo eliminates the need for query/key/value projections and softmax attention, replacing them with fixed linear transformations and polynomial activations.  
  This results in lower computational cost—linear in $|S|$, rather than quadratic—as well as a simpler and more transparent architecture.

In short, while DeepHalo draws conceptual inspiration from Transformer-style aggregation, it diverges in architectural design to achieve interpretable, order-controllable, and computationally efficient modeling of contextual choice effects. We thank the reviewer again for raising this connection and will add a discussion in the final version to highlight these points explicitly.

#### 2. Model size comparison

We thank the reviewer for raising the question regarding the model scale. To address this, we computed the number of trainable parameters under the **Expedia experiment setting**, where the input item feature dimension is set to 10 across all models. The results are summarized below:

| Model      | Number of Parameters |
|------------|----------------------|
| TCNet      | 118,209              |
| **DeepHalo**   | **53,833**               |
| RUMNet     | 53,900               |
| TasteNet   | 35,851               |
| DLCL       | 210                  |
| FATE       | 44,363               |
| MLP        | 42,601               |
| ResLogit   | 2,720                |
| MNL        | 10                   |

#### 3. Featureless setting: model comparison with controlled parameter count

We thank the reviewer for their suggestion. In the **featureless setting**, we have added results for three representative baselines: **FATE**, **TCNet**, and **Mixed MNL**. To ensure fairness and focus on architectural differences, we controlled the parameter size of all neural network–based models to be **approximately 1K parameters**. The results are shown below:

| Model         | Hotel (Train/Test) | SFOshop (Train/Test) | SFOwork (Train/Test) |
|---------------|--------------------|------------------------|-----------------------|
| MNL           | 0.7743 / 0.7743    | 1.7281 / 1.7262        | 0.9423 / 0.9482       |
| MLP           | 0.7569 / 0.7523    | 1.5556 / 1.5523        | 0.8074 / 0.8120       |
| CMNL          | 0.7566 / 0.7561    | 1.5676 / 1.5686        | 0.8116 / 0.8164       |
| Mixed MNL     | 0.7635 / 0.7613    | 1.5599 / 1.5577        | 0.8092 / 0.8153       |
| FateNet       | 0.7575 / 0.7568    | 1.5726 / 1.5765        | 0.8133 / 0.8167       |
| TCNet         | **0.7467** / 0.7670| 1.5694 / 1.5742        | 0.8114 / 0.8145       |
| **DeepHalo** (Ours) | 0.7479 / **0.7483** | **1.5385** / **1.5263** | **0.8040** / **0.8066** |

